# ğŸš€ Prerequisites for Generative AI

<div align="center">

![GenAI](https://img.shields.io/badge/Generative_AI-Prerequisites-blueviolet?style=for-the-badge)
![Topics](https://img.shields.io/badge/Topics-7-green?style=for-the-badge)
![Duration](https://img.shields.io/badge/Duration-4--6_weeks-orange?style=for-the-badge)

*Master the foundational knowledge required for VAEs, GANs, Diffusion Models, and Transformers*

</div>

---

## ğŸ“š Topics Overview

| # | Topic | What You'll Learn | Why It Matters |
|:-:|:------|:------------------|:---------------|
| 01 | [ğŸ”¢ Linear Algebra](./01_linear_algebra/) | Matrices, vectors, SVD, eigenvalues | Every neural network layer is a matrix operation |
| 02 | [ğŸ“Š Probability & Statistics](./02_probability_and_statistics/) | Distributions, Bayes rule, sampling | GenAI = learning probability distributions |
| 03 | [ğŸ“ Information Theory](./03_information_theory/) | Entropy, KL divergence, cross-entropy | Loss functions and model evaluation |
| 04 | [âš¡ Optimization Methods](./04_optimization_methods/) | SGD, Adam, GAN training | How models learn from data |
| 05 | [ğŸ”¥ PyTorch Basics](./05_pytorch_basics/) | Tensors, autograd, nn.Module | The framework for building GenAI |
| 06 | [ğŸ–¼ï¸ CNNs](./06_convolutional_neural_networks/) | Convolutions, U-Net, upsampling | Image generation architectures |
| 07 | [ğŸ“¦ Datasets & Preprocessing](./07_datasets_and_preprocessing/) | Data loading, normalization, augmentation | Data quality = model quality |

---

## ğŸ¯ Learning Path

<div align="center">

![Learning Path](./images/learning_path.svg)

</div>

---

## ğŸ”— How Topics Connect to GenAI Models

<div align="center">

![GenAI Connections](./images/genai_connections.svg)

</div>

<table>
<tr>
<td width="50%">

### ğŸ”„ VAE (Variational Autoencoder)
- **Linear Algebra**: Encoder/decoder are matrix operations
- **Probability**: Gaussian latent space, reparameterization trick
- **Information Theory**: ELBO = Reconstruction - KL divergence
- **Optimization**: Adam optimizer, KL annealing
- **PyTorch**: nn.Module for encoder/decoder
- **CNNs**: Convolutional encoder/decoder for images

</td>
<td width="50%">

### ğŸ­ GAN (Generative Adversarial Network)
- **Linear Algebra**: Generator/discriminator weight matrices
- **Probability**: Implicit distribution learning
- **Information Theory**: JS divergence (original), Wasserstein (WGAN)
- **Optimization**: Two-player game, TTUR, spectral normalization
- **PyTorch**: Two models, two optimizers
- **CNNs**: DCGAN, StyleGAN architectures

</td>
</tr>
<tr>
<td width="50%">

### ğŸŒŠ Diffusion Models (Stable Diffusion, DALL-E)
- **Linear Algebra**: U-Net weights, attention QKV
- **Probability**: Gaussian noise, score functions, Langevin dynamics
- **Information Theory**: Denoising score matching
- **Optimization**: AdamW, EMA weights
- **PyTorch**: U-Net implementation, noise scheduling
- **CNNs**: U-Net encoder-decoder with skip connections

</td>
<td width="50%">

### ğŸ¤– Transformers (GPT, Vision Transformers)
- **Linear Algebra**: Attention = QK^T Ã— V, all linear layers
- **Probability**: Autoregressive p(x_t | x_<t)
- **Information Theory**: Cross-entropy loss, perplexity
- **Optimization**: AdamW, warmup, cosine decay
- **PyTorch**: nn.MultiheadAttention, positional encoding

</td>
</tr>
</table>

---

## â±ï¸ Suggested Time Investment

| Topic | Time | Priority |
|:------|:-----|:---------|
| ğŸ”¢ Linear Algebra | 1-2 weeks | ğŸ”´ **Critical** |
| ğŸ“Š Probability & Statistics | 1-2 weeks | ğŸ”´ **Critical** |
| ğŸ“ Information Theory | 3-5 days | ğŸŸ¡ Important |
| âš¡ Optimization | 3-5 days | ğŸŸ¡ Important |
| ğŸ”¥ PyTorch Basics | 1 week | ğŸ”´ **Critical** |
| ğŸ–¼ï¸ CNNs | 3-5 days | ğŸŸ¡ Important |
| ğŸ“¦ Datasets & Preprocessing | 2-3 days | ğŸŸ¢ Practical |

> **Total: 4-6 weeks** for solid foundations

---

## ğŸ“– Each Topic Includes

<table>
<tr>
<td align="center">
<h3>ğŸ¨</h3>
<b>Visual Overview</b><br>
SVG diagram of key concepts
</td>
<td align="center">
<h3>ğŸ¯</h3>
<b>Where & Why</b><br>
Practical applications in GenAI
</td>
<td align="center">
<h3>ğŸ“</h3>
<b>Theory</b><br>
Mathematical foundations with proofs
</td>
</tr>
<tr>
<td align="center">
<h3>ğŸ’»</h3>
<b>Examples</b><br>
Code snippets and formulas
</td>
<td align="center">
<h3>âœï¸</h3>
<b>Exercises</b><br>
Practice problems
</td>
<td align="center">
<h3>ğŸ“š</h3>
<b>References</b><br>
Papers, books, online resources
</td>
</tr>
</table>

---

## ğŸš€ Quick Start

<table>
<tr>
<td width="50%">

### ğŸ†• New to GenAI?

Start with:
1. `05_pytorch_basics` - Get comfortable with the framework
2. `01_linear_algebra` - Understand what happens in layers
3. `02_probability_and_statistics` - Understand what models learn

</td>
<td width="50%">

### ğŸ“ Already familiar with ML?

Focus on:
1. `03_information_theory` - VAE/GAN loss functions
2. `04_optimization_methods` - GAN training specifics
3. `06_convolutional_neural_networks` - U-Net for diffusion

</td>
</tr>
</table>

---

## ğŸ“ Folder Structure

| Folder | Contents |
|:-------|:---------|
| ğŸ“‚ `images/` | Main diagrams (learning path, connections) |
| ğŸ“‚ `01_linear_algebra/` | README + `images/matrix_operations_genai.svg` |
| ğŸ“‚ `02_probability_and_statistics/` | README + `images/probability_genai.svg` |
| ğŸ“‚ `03_information_theory/` | README + `images/information_theory_genai.svg` |
| ğŸ“‚ `04_optimization_methods/` | README + `images/optimization_genai.svg` |
| ğŸ“‚ `05_pytorch_basics/` | README + `images/pytorch_genai.svg` |
| ğŸ“‚ `06_convolutional_neural_networks/` | README + `images/cnn_genai.svg` |
| ğŸ“‚ `07_datasets_and_preprocessing/` | README + `images/datasets_preprocessing_genai.svg` |

---

## ğŸ“ After Completing Prerequisites

You'll be ready to study:

<table>
<tr>
<td align="center">
<h3>ğŸ”„ VAE</h3>
Variational<br>Autoencoders
</td>
<td align="center">
<h3>ğŸ­ GAN</h3>
Generative Adversarial<br>Networks
</td>
<td align="center">
<h3>ğŸŒŠ Diffusion</h3>
DDPM, Stable Diffusion
</td>
<td align="center">
<h3>ğŸ¤– Transformers</h3>
GPT, Vision<br>Transformers
</td>
<td align="center">
<h3>ğŸŒˆ Multimodal</h3>
CLIP, DALL-E
</td>
</tr>
</table>

---

<div align="center">

*Start with any topic that interests you, but make sure to cover all of them before diving deep into GenAI architectures!*

**Made with â¤ï¸ for the GenAI community**

</div>
