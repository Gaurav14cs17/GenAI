# ğŸ“– Chapter 7: Model Architecture

<div align="center">

*How to modify DiT for solution function learning*

</div>

---

## ğŸ—ï¸ Overview

SoFlow uses **Diffusion Transformer (DiT)** with one key modification:

![Architecture Overview](./images/architecture.svg)

> ğŸ”‘ **Key Change**: Add target time `s` as a new input!

---

## ğŸ”„ Standard DiT vs SoFlow DiT

### Standard DiT (Velocity)

```python
class StandardDiT:
    def forward(self, x_t, t, y):
        # Inputs: noisy image, time, class
        return velocity
```

### SoFlow DiT (Solution)

```python
class SoFlowDiT:
    def forward(self, x_t, t, s, y):  # â† Added 's'!
        # Inputs: noisy image, current time, TARGET time, class
        return x_s
```

---

## ğŸ§± Architecture Components

### 1ï¸âƒ£ Patch Embedding

Convert image to sequence of tokens:

```python
patches = patchify(image)  # [B, C, H, W] â†’ [B, N, D]
tokens = linear(patches) + pos_embedding
```

### 2ï¸âƒ£ Time Embeddings (Two of them!)

```python
class TimestepEmbedder(nn.Module):
    def forward(self, t):
        # Sinusoidal â†’ MLP
        freqs = sin_cos_embedding(t)
        return mlp(freqs)

# SoFlow uses TWO embedders
t_emb = t_embedder(t)  # Current time
s_emb = s_embedder(s)  # Target time â† NEW!
```

### 3ï¸âƒ£ Combined Conditioning

```python
# All conditions combined
c = t_emb + s_emb + y_emb
```

### 4ï¸âƒ£ Transformer Blocks with AdaLN

```python
class DiTBlock(nn.Module):
    def forward(self, x, c):
        # AdaLN-conditioned self-attention
        x = x + attn(adaln(x, c))
        x = x + mlp(adaln(x, c))
        return x
```

---

## ğŸ›ï¸ Adaptive Layer Normalization

### Standard LayerNorm
```
out = Î³ Â· normalize(x) + Î²
```

### AdaLN (Adaptive)
```
Î³, Î² = linear(c)  # Learn from conditioning
out = (1 + Î³) Â· normalize(x) + Î²
```

```python
class AdaLayerNorm(nn.Module):
    def forward(self, x, c):
        shift, scale = self.linear(c).chunk(2, dim=-1)
        return self.norm(x) * (1 + scale) + shift
```

---

## ğŸ“ Model Sizes

| Model | Depth | Hidden | Heads | Params |
|:-----:|:-----:|:------:|:-----:|:------:|
| S/2 | 12 | 384 | 6 | ~33M |
| B/2 | 12 | 768 | 12 | ~130M |
| L/2 | 24 | 1024 | 16 | ~458M |
| XL/2 | 28 | 1152 | 16 | ~675M |

> `/2` means patch size = 2

---

## ğŸ”€ Residual Output

The model predicts a **displacement**, not the final image:

```python
def forward(self, x_t, t, s, y):
    displacement = self.backbone(x_t, t, s, y)
    return x_t + displacement  # Residual!
```

### Why Residual?

| Benefit | Explanation |
|:-------:|:-----------:|
| **Identity Init** | `f(x,t,t) â‰ˆ x` when displacement â‰ˆ 0 |
| **Stable Training** | Learn small deltas, not absolute values |
| **Better Gradients** | Residual connections help gradient flow |

---

## ğŸ–¼ï¸ Full Forward Pass

```python
class SoFlowDiT(nn.Module):
    def forward(self, x, t, s, y):
        # 1. Patchify + position embedding
        x = self.patch_embed(x) + self.pos_embed
        
        # 2. Time embeddings (both t and s!)
        t_emb = self.t_embedder(t)
        s_emb = self.s_embedder(s)  # â† NEW
        y_emb = self.y_embedder(y)
        c = t_emb + s_emb + y_emb
        
        # 3. Transformer blocks
        for block in self.blocks:
            x = block(x, c)
        
        # 4. Final layer + unpatchify
        x = self.final_layer(x, c)
        displacement = self.unpatchify(x)
        
        # 5. Residual connection
        return input_x + displacement
```

---

## ğŸ”‘ Key Takeaways

<table>
<tr>
<td>

### ğŸ“š Architecture
- DiT backbone
- Two time embedders (t and s)
- AdaLN conditioning
- Residual output

</td>
<td>

### ğŸ’¡ Key Change
Just add one embedder for `s`!

Everything else stays the same.

</td>
</tr>
</table>

---

## ğŸ“š What's Next?

How does SoFlow compare to other methods?

<div align="center">

**[â† Chapter 6: CFG](../06-cfg/README.md)** | **[Chapter 8: Comparison â†’](../08-comparison/README.md)**

</div>

---

<div align="center">

*Chapter 7 of 9 â€¢ [Back to Index](../README.md)*

</div>
