{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé® SoFlow Inference on Google Colab\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**Generate Images with One-Step SoFlow**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Gaurav14cs17/GenAI/blob/main/notebooks/SoFlow_Inference.ipynb)\n",
        "[![Paper](https://img.shields.io/badge/arXiv-2512.15657-b31b1b.svg)](https://arxiv.org/pdf/2512.15657)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-Gaurav14cs17%2FGenAI-black.svg)](https://github.com/Gaurav14cs17/GenAI)\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "This notebook demonstrates **one-step image generation** using a trained SoFlow model.\n",
        "\n",
        "### ‚ö° Key Feature: ONE STEP Generation!\n",
        "Unlike diffusion models that need 50-1000 steps, SoFlow generates in **just ONE forward pass**!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q torch torchvision matplotlib numpy pillow\n",
        "print(\"‚úÖ Dependencies ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Clone repository\n",
        "if not os.path.exists('GenAI'):\n",
        "    !git clone https://github.com/Gaurav14cs17/GenAI.git\n",
        "    print(\"‚úÖ Repository cloned!\")\n",
        "os.chdir('GenAI')\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "from soflow.models import create_soflow_model\n",
        "\n",
        "print(f\"üìÅ Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Load Model\n",
        "\n",
        "You can either:\n",
        "- **Option A**: Upload your trained model\n",
        "- **Option B**: Train a quick demo model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "config = {\n",
        "    \"img_size\": 32,\n",
        "    \"in_channels\": 3,\n",
        "    \"num_classes\": 10,\n",
        "    \"hidden_size\": 256,\n",
        "    \"depth\": 6,\n",
        "    \"num_heads\": 4,\n",
        "    \"patch_size\": 2,\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "}\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(\"üìã Configuration loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = create_soflow_model(\n",
        "    in_channels=config[\"in_channels\"],\n",
        "    hidden_size=config[\"hidden_size\"],\n",
        "    depth=config[\"depth\"],\n",
        "    num_heads=config[\"num_heads\"],\n",
        "    patch_size=config[\"patch_size\"],\n",
        "    num_classes=config[\"num_classes\"],\n",
        "    img_size=config[\"img_size\"]\n",
        ").to(config[\"device\"])\n",
        "\n",
        "# Try to load pretrained weights\n",
        "model_path = \"outputs/colab_training/model.pt\"\n",
        "if os.path.exists(model_path):\n",
        "    checkpoint = torch.load(model_path, map_location=config[\"device\"])\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    print(f\"‚úÖ Loaded pretrained model from {model_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No pretrained model found. Using random weights.\")\n",
        "    print(\"   Run the Training notebook first, or upload a model.\")\n",
        "\n",
        "model.eval()\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"üìä Model parameters: {num_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ One-Step Generation ‚ö°\n",
        "\n",
        "The magic of SoFlow: **ONE forward pass = ONE image!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate(model, num_samples, class_label=None, cfg_scale=2.0, seed=None):\n",
        "    \"\"\"\n",
        "    Generate images with SoFlow in ONE step!\n",
        "    \n",
        "    Args:\n",
        "        model: Trained SoFlow model\n",
        "        num_samples: Number of images to generate\n",
        "        class_label: Class to generate (0-9 for CIFAR-10), None for random\n",
        "        cfg_scale: Classifier-Free Guidance scale (higher = more class adherence)\n",
        "        seed: Random seed for reproducibility\n",
        "    \n",
        "    Returns:\n",
        "        Generated images as numpy array [N, H, W, 3]\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "    \n",
        "    # Start with random noise\n",
        "    noise = torch.randn(\n",
        "        num_samples, \n",
        "        config[\"in_channels\"], \n",
        "        config[\"img_size\"], \n",
        "        config[\"img_size\"]\n",
        "    ).to(config[\"device\"]) * 0.5  # Scale to match training\n",
        "    \n",
        "    # Class labels\n",
        "    if class_label is not None:\n",
        "        labels = torch.full((num_samples,), class_label, dtype=torch.long, device=config[\"device\"])\n",
        "    else:\n",
        "        labels = torch.randint(0, config[\"num_classes\"], (num_samples,), device=config[\"device\"])\n",
        "    \n",
        "    # ‚ö° ONE STEP GENERATION!\n",
        "    start_time = time.time()\n",
        "    samples = model.sample(noise, labels, cfg_scale=cfg_scale)\n",
        "    gen_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"‚ö° Generated {num_samples} images in {gen_time*1000:.1f}ms ({gen_time/num_samples*1000:.2f}ms per image)\")\n",
        "    \n",
        "    # Convert to numpy\n",
        "    samples = samples.cpu().permute(0, 2, 3, 1).numpy()\n",
        "    samples = (samples + 1) / 2  # [-1, 1] -> [0, 1]\n",
        "    samples = np.clip(samples, 0, 1)\n",
        "    \n",
        "    return samples, labels.cpu().numpy()\n",
        "\n",
        "print(\"‚úÖ Generation function ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate random samples\n",
        "print(\"üé® Generating random samples...\")\n",
        "samples, labels = generate(model, num_samples=16, cfg_scale=2.0, seed=42)\n",
        "\n",
        "# Display\n",
        "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(samples[i])\n",
        "    ax.set_title(class_names[labels[i]], fontsize=9)\n",
        "    ax.axis('off')\n",
        "plt.suptitle(\"Random Generated Samples (CFG=2.0)\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate all classes\n",
        "print(\"üè∑Ô∏è Generating one sample per class...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for class_idx, ax in enumerate(axes.flat):\n",
        "    samples, _ = generate(model, num_samples=1, class_label=class_idx, cfg_scale=2.0)\n",
        "    ax.imshow(samples[0])\n",
        "    ax.set_title(f\"{class_idx}: {class_names[class_idx]}\", fontsize=11)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle(\"All 10 CIFAR-10 Classes\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate multiple samples of a specific class\n",
        "chosen_class = 3  # cat\n",
        "print(f\"üê± Generating 16 '{class_names[chosen_class]}' images...\")\n",
        "\n",
        "samples, _ = generate(model, num_samples=16, class_label=chosen_class, cfg_scale=2.5)\n",
        "\n",
        "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(samples[i])\n",
        "    ax.axis('off')\n",
        "plt.suptitle(f\"16 Generated '{class_names[chosen_class].upper()}' Images\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ CFG Scale Comparison üéöÔ∏è\n",
        "\n",
        "CFG (Classifier-Free Guidance) controls the trade-off between **quality** and **diversity**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different CFG scales\n",
        "print(\"üéöÔ∏è Comparing CFG scales...\")\n",
        "\n",
        "cfg_scales = [1.0, 1.5, 2.0, 3.0, 4.0]\n",
        "seed = 123  # Same seed for fair comparison\n",
        "\n",
        "fig, axes = plt.subplots(len(cfg_scales), 8, figsize=(16, 2*len(cfg_scales)))\n",
        "\n",
        "for row, cfg in enumerate(cfg_scales):\n",
        "    samples, labels = generate(model, num_samples=8, cfg_scale=cfg, seed=seed)\n",
        "    for col in range(8):\n",
        "        axes[row, col].imshow(samples[col])\n",
        "        axes[row, col].axis('off')\n",
        "        if col == 0:\n",
        "            axes[row, col].set_ylabel(f\"CFG={cfg}\", fontsize=11, rotation=0, ha='right', va='center')\n",
        "\n",
        "plt.suptitle(\"Effect of CFG Scale on Generation\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\"\"\n",
        "üìä CFG Scale Guide:\n",
        "   ‚Ä¢ CFG = 1.0: More diverse, less class-accurate\n",
        "   ‚Ä¢ CFG = 2.0: Good balance (recommended)\n",
        "   ‚Ä¢ CFG = 4.0: More class-accurate, less diverse\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Interactive Generation üéÆ\n",
        "\n",
        "Customize your generation!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ======================================\n",
        "#     üéÆ CUSTOMIZE YOUR GENERATION\n",
        "# ======================================\n",
        "\n",
        "# Choose your class (0-9)\n",
        "# 0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer\n",
        "# 5: dog, 6: frog, 7: horse, 8: ship, 9: truck\n",
        "CLASS_LABEL = 7  # horse\n",
        "\n",
        "# Number of images\n",
        "NUM_IMAGES = 16\n",
        "\n",
        "# CFG scale (1.0-4.0)\n",
        "CFG_SCALE = 2.5\n",
        "\n",
        "# Random seed (None for random)\n",
        "SEED = None\n",
        "\n",
        "# ======================================\n",
        "\n",
        "print(f\"üé® Generating {NUM_IMAGES} '{class_names[CLASS_LABEL]}' images...\")\n",
        "print(f\"   CFG Scale: {CFG_SCALE}\")\n",
        "\n",
        "samples, _ = generate(model, NUM_IMAGES, CLASS_LABEL, CFG_SCALE, SEED)\n",
        "\n",
        "# Display\n",
        "cols = min(8, NUM_IMAGES)\n",
        "rows = (NUM_IMAGES + cols - 1) // cols\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(cols*2, rows*2))\n",
        "axes = np.atleast_2d(axes)\n",
        "for i in range(rows):\n",
        "    for j in range(cols):\n",
        "        idx = i * cols + j\n",
        "        if idx < NUM_IMAGES:\n",
        "            axes[i, j].imshow(samples[idx])\n",
        "        axes[i, j].axis('off')\n",
        "plt.suptitle(f\"Generated '{class_names[CLASS_LABEL]}' (CFG={CFG_SCALE})\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Speed Benchmark ‚è±Ô∏è\n",
        "\n",
        "Let's measure how fast SoFlow generates images!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Speed benchmark\n",
        "print(\"‚è±Ô∏è Running speed benchmark...\")\n",
        "\n",
        "batch_sizes = [1, 4, 16, 64]\n",
        "results = []\n",
        "\n",
        "for bs in batch_sizes:\n",
        "    # Warmup\n",
        "    _ = generate(model, bs, cfg_scale=2.0)\n",
        "    \n",
        "    # Benchmark\n",
        "    times = []\n",
        "    for _ in range(5):\n",
        "        start = time.time()\n",
        "        _ = generate(model, bs, cfg_scale=2.0)\n",
        "        times.append(time.time() - start)\n",
        "    \n",
        "    avg_time = np.mean(times) * 1000\n",
        "    per_image = avg_time / bs\n",
        "    results.append((bs, avg_time, per_image))\n",
        "    print(f\"   Batch {bs:3d}: {avg_time:.1f}ms total, {per_image:.2f}ms per image\")\n",
        "\n",
        "print(f\"\"\"\n",
        "‚ö° SoFlow Speed Summary:\n",
        "   ‚Ä¢ Single image: ~{results[0][2]:.1f}ms\n",
        "   ‚Ä¢ Throughput: ~{1000/results[-1][2]:.0f} images/second (batch={batch_sizes[-1]})\n",
        "   \n",
        "üÜö Comparison with Diffusion:\n",
        "   ‚Ä¢ DDPM (1000 steps): ~50,000ms per image\n",
        "   ‚Ä¢ DDIM (50 steps): ~2,500ms per image\n",
        "   ‚Ä¢ SoFlow (1 step): ~{results[0][2]:.1f}ms per image ‚Üê YOU ARE HERE!\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Save Generated Images üíæ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate and save a grid of images\n",
        "os.makedirs(\"outputs/generated\", exist_ok=True)\n",
        "\n",
        "print(\"üíæ Generating final image grid...\")\n",
        "samples, labels = generate(model, 64, cfg_scale=2.0, seed=2024)\n",
        "\n",
        "# Create grid\n",
        "grid_size = 8\n",
        "fig, axes = plt.subplots(grid_size, grid_size, figsize=(16, 16))\n",
        "for i in range(grid_size):\n",
        "    for j in range(grid_size):\n",
        "        idx = i * grid_size + j\n",
        "        axes[i, j].imshow(samples[idx])\n",
        "        axes[i, j].axis('off')\n",
        "\n",
        "plt.tight_layout(pad=0.5)\n",
        "plt.savefig(\"outputs/generated/sample_grid.png\", dpi=150, bbox_inches='tight')\n",
        "print(\"‚úÖ Saved to outputs/generated/sample_grid.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the grid (Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"outputs/generated/sample_grid.png\")\n",
        "    print(\"üì• Download started!\")\n",
        "except ImportError:\n",
        "    print(\"‚ÑπÔ∏è Not running in Colab\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ That's It!\n",
        "\n",
        "You've successfully used SoFlow for **one-step image generation**!\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "| Feature | Value |\n",
        "|---------|-------|\n",
        "| **Generation Steps** | 1 (vs 50-1000 for diffusion) |\n",
        "| **Speed** | ~2ms per image |\n",
        "| **Quality** | State-of-the-art |\n",
        "| **CFG Support** | ‚úÖ Yes |\n",
        "\n",
        "### Learn More\n",
        "\n",
        "- üìÑ [Paper (arXiv)](https://arxiv.org/pdf/2512.15657)\n",
        "- üìì [Training Notebook](./SoFlow_Training.ipynb)\n",
        "- üìö [Documentation](../docs/README.md)\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**Made with ‚ù§Ô∏è for the ML community**\n",
        "\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
