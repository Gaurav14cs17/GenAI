# Training Configuration for ImageNet 256x256
# Standard training setup following the SoFlow paper

data:
  path: /path/to/imagenet  # Update this path
  use_latents: true  # Use pre-extracted VAE latents
  latent_path: null  # Optional: custom latent path
  batch_size: 256  # Per-GPU batch size
  num_workers: 8

training:
  epochs: 400
  
  # Optimizer
  optimizer:
    name: adamw
    lr: 1.0e-4
    weight_decay: 0.0
    betas: [0.9, 0.999]
  
  # Learning rate schedule
  scheduler:
    warmup_steps: 1000
    type: cosine  # cosine decay after warmup
  
  # Gradient clipping
  grad_clip: 1.0
  
  # Mixed precision
  mixed_precision: bf16

# Loss configuration
loss:
  lambda_fm: 1.0  # Flow Matching loss weight
  lambda_cons: 1.0  # Consistency loss weight
  sigma_min: 0.0  # Minimum sigma for FM
  use_adaptive_consistency: true
  consistency_warmup: 1000

# EMA configuration
ema:
  decay: 0.9999
  warmup_steps: 0
  update_every: 1

