{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ SoFlow Training on Google Colab\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**Train SoFlow: One-Step Image Generation**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Gaurav14cs17/GenAI/blob/main/notebooks/SoFlow_Training.ipynb)\n",
        "[![Paper](https://img.shields.io/badge/arXiv-2512.15657-b31b1b.svg)](https://arxiv.org/pdf/2512.15657)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-Gaurav14cs17%2FGenAI-black.svg)](https://github.com/Gaurav14cs17/GenAI)\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "This notebook trains a SoFlow model on CIFAR-10 dataset. You'll learn:\n",
        "- How to set up the training environment\n",
        "- Understanding the training loop\n",
        "- Monitoring loss curves\n",
        "- Generating samples during training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Setup Environment\n",
        "\n",
        "First, let's check GPU availability and install dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision tqdm matplotlib numpy pillow\n",
        "print(\"‚úÖ Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Clone Repository & Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Clone the repository (if not already cloned)\n",
        "if not os.path.exists('GenAI'):\n",
        "    !git clone https://github.com/Gaurav14cs17/GenAI.git\n",
        "    print(\"‚úÖ Repository cloned!\")\n",
        "else:\n",
        "    print(\"‚úÖ Repository already exists!\")\n",
        "\n",
        "# Change to the repository directory\n",
        "os.chdir('GenAI')\n",
        "print(f\"üìÅ Working directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "# Import SoFlow modules\n",
        "from soflow.models import create_soflow_model, DIT_MODELS\n",
        "from soflow.losses import SoFlowLoss\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"üì¶ Available models: {list(DIT_MODELS.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Training Configuration\n",
        "\n",
        "Adjust these parameters based on your GPU memory and training needs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===========================================\n",
        "#           TRAINING CONFIGURATION\n",
        "# ===========================================\n",
        "\n",
        "config = {\n",
        "    # Dataset\n",
        "    \"dataset\": \"cifar10\",\n",
        "    \"img_size\": 32,\n",
        "    \"in_channels\": 3,\n",
        "    \"num_classes\": 10,\n",
        "    \n",
        "    # Model (use smaller model for Colab)\n",
        "    \"hidden_size\": 256,\n",
        "    \"depth\": 6,\n",
        "    \"num_heads\": 4,\n",
        "    \"patch_size\": 2,\n",
        "    \n",
        "    # Training\n",
        "    \"epochs\": 50,\n",
        "    \"batch_size\": 128,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"weight_decay\": 0.0,\n",
        "    \n",
        "    # Loss weights\n",
        "    \"lambda_fm\": 1.0,\n",
        "    \"lambda_cons\": 0.1,\n",
        "    \n",
        "    # Sampling\n",
        "    \"cfg_scale\": 2.0,\n",
        "    \"save_every\": 10,\n",
        "    \n",
        "    # Device\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "}\n",
        "\n",
        "print(\"üìã Training Configuration:\")\n",
        "for k, v in config.items():\n",
        "    print(f\"   {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # [-1, 1]\n",
        "])\n",
        "\n",
        "# Load CIFAR-10\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root='./data', \n",
        "    train=True, \n",
        "    download=True, \n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=config[\"batch_size\"], \n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Class names for visualization\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(f\"‚úÖ Dataset loaded!\")\n",
        "print(f\"   Training samples: {len(train_dataset)}\")\n",
        "print(f\"   Batches per epoch: {len(train_loader)}\")\n",
        "print(f\"   Classes: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some training samples\n",
        "def show_samples(images, labels, title=\"Training Samples\"):\n",
        "    fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(images):\n",
        "            img = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "            img = (img + 1) / 2  # [-1, 1] -> [0, 1]\n",
        "            ax.imshow(np.clip(img, 0, 1))\n",
        "            ax.set_title(class_names[labels[i]] if isinstance(labels[i], int) else class_names[labels[i].item()], fontsize=8)\n",
        "        ax.axis('off')\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show samples\n",
        "sample_batch, sample_labels = next(iter(train_loader))\n",
        "show_samples(sample_batch[:16], sample_labels[:16])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Create Model & Training Components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create SoFlow model\n",
        "model = create_soflow_model(\n",
        "    in_channels=config[\"in_channels\"],\n",
        "    hidden_size=config[\"hidden_size\"],\n",
        "    depth=config[\"depth\"],\n",
        "    num_heads=config[\"num_heads\"],\n",
        "    patch_size=config[\"patch_size\"],\n",
        "    num_classes=config[\"num_classes\"],\n",
        "    img_size=config[\"img_size\"]\n",
        ").to(config[\"device\"])\n",
        "\n",
        "# Count parameters\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"‚úÖ Model created!\")\n",
        "print(f\"   Parameters: {num_params:,} ({num_params/1e6:.2f}M)\")\n",
        "\n",
        "# Create loss function\n",
        "loss_fn = SoFlowLoss(\n",
        "    lambda_fm=config[\"lambda_fm\"],\n",
        "    lambda_cons=config[\"lambda_cons\"]\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config[\"learning_rate\"],\n",
        "    weight_decay=config[\"weight_decay\"]\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer, \n",
        "    T_max=config[\"epochs\"] * len(train_loader)\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Loss function and optimizer created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Training Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_step(model, loss_fn, batch, optimizer, scheduler, step, total_steps):\n",
        "    \"\"\"Single training step.\"\"\"\n",
        "    x_0, y = batch\n",
        "    x_0 = x_0.to(config[\"device\"])\n",
        "    y = y.to(config[\"device\"])\n",
        "    \n",
        "    # Scale noise to match data std (~0.5)\n",
        "    x_1 = torch.randn_like(x_0) * 0.5\n",
        "    \n",
        "    # Forward pass\n",
        "    loss_dict = loss_fn(\n",
        "        model, x_0, x_1, y, \n",
        "        step=step, \n",
        "        total_steps=total_steps, \n",
        "        return_dict=True\n",
        "    )\n",
        "    loss = loss_dict[\"loss\"]\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    \n",
        "    return {k: v.item() for k, v in loss_dict.items()}\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_samples(model, num_samples, cfg_scale):\n",
        "    \"\"\"Generate samples for visualization.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Generate noise (scaled to match data)\n",
        "    noise = torch.randn(\n",
        "        num_samples, \n",
        "        config[\"in_channels\"], \n",
        "        config[\"img_size\"], \n",
        "        config[\"img_size\"]\n",
        "    ).to(config[\"device\"]) * 0.5\n",
        "    \n",
        "    # Labels (one per class, repeating)\n",
        "    labels = torch.arange(config[\"num_classes\"]).to(config[\"device\"])\n",
        "    labels = labels.repeat(num_samples // config[\"num_classes\"] + 1)[:num_samples]\n",
        "    \n",
        "    # Generate with one step!\n",
        "    samples = model.sample(noise, labels, cfg_scale=cfg_scale)\n",
        "    \n",
        "    model.train()\n",
        "    return samples, labels\n",
        "\n",
        "print(\"‚úÖ Training functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training history\n",
        "history = {\n",
        "    \"loss\": [],\n",
        "    \"loss_fm\": [],\n",
        "    \"loss_cons\": [],\n",
        "    \"lr\": []\n",
        "}\n",
        "\n",
        "# Output directory\n",
        "os.makedirs(\"outputs/colab_training\", exist_ok=True)\n",
        "os.makedirs(\"outputs/colab_training/samples\", exist_ok=True)\n",
        "\n",
        "# Total steps\n",
        "total_steps = config[\"epochs\"] * len(train_loader)\n",
        "global_step = 0\n",
        "\n",
        "print(f\"üöÄ Starting training for {config['epochs']} epochs...\")\n",
        "print(f\"   Total steps: {total_steps:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main training loop\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "    model.train()\n",
        "    epoch_losses = []\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']}\")\n",
        "    \n",
        "    for batch in pbar:\n",
        "        metrics = train_step(\n",
        "            model, loss_fn, batch, optimizer, scheduler,\n",
        "            step=global_step, total_steps=total_steps\n",
        "        )\n",
        "        \n",
        "        epoch_losses.append(metrics[\"loss\"])\n",
        "        history[\"loss\"].append(metrics[\"loss\"])\n",
        "        history[\"loss_fm\"].append(metrics.get(\"loss_fm\", 0))\n",
        "        history[\"loss_cons\"].append(metrics.get(\"loss_cons\", 0))\n",
        "        history[\"lr\"].append(scheduler.get_last_lr()[0])\n",
        "        \n",
        "        global_step += 1\n",
        "        pbar.set_postfix({\"loss\": f\"{metrics['loss']:.4f}\"})\n",
        "    \n",
        "    avg_loss = np.mean(epoch_losses)\n",
        "    print(f\"üìä Epoch {epoch+1}: avg_loss = {avg_loss:.4f}\")\n",
        "    \n",
        "    # Generate and save samples periodically\n",
        "    if (epoch + 1) % config[\"save_every\"] == 0 or epoch == 0:\n",
        "        samples, labels = generate_samples(model, 16, config[\"cfg_scale\"])\n",
        "        show_samples(samples, labels, f\"Epoch {epoch+1} Samples (CFG={config['cfg_scale']})\")\n",
        "\n",
        "print(\"\\n‚úÖ Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Visualize Results üìä\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Total loss\n",
        "axes[0].plot(history[\"loss\"], alpha=0.5, label=\"Raw\")\n",
        "window = min(100, len(history[\"loss\"]) // 10 + 1)\n",
        "if window > 1 and len(history[\"loss\"]) > window:\n",
        "    smoothed = np.convolve(history[\"loss\"], np.ones(window)/window, mode='valid')\n",
        "    axes[0].plot(smoothed, label=\"Smoothed\", linewidth=2)\n",
        "axes[0].set_xlabel(\"Step\")\n",
        "axes[0].set_ylabel(\"Loss\")\n",
        "axes[0].set_title(\"Total Loss\")\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# FM vs Cons loss\n",
        "axes[1].plot(history[\"loss_fm\"], label=\"FM Loss\", alpha=0.7)\n",
        "axes[1].plot(history[\"loss_cons\"], label=\"Cons Loss\", alpha=0.7)\n",
        "axes[1].set_xlabel(\"Step\")\n",
        "axes[1].set_ylabel(\"Loss\")\n",
        "axes[1].set_title(\"Loss Components\")\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate\n",
        "axes[2].plot(history[\"lr\"])\n",
        "axes[2].set_xlabel(\"Step\")\n",
        "axes[2].set_ylabel(\"Learning Rate\")\n",
        "axes[2].set_title(\"Learning Rate Schedule\")\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/colab_training/loss_curves.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate final samples with different CFG scales\n",
        "print(\"üé® Generating samples with different CFG scales...\")\n",
        "\n",
        "fig, axes = plt.subplots(3, 10, figsize=(20, 6))\n",
        "cfg_scales = [1.0, 2.0, 4.0]\n",
        "\n",
        "for i, cfg in enumerate(cfg_scales):\n",
        "    samples, labels = generate_samples(model, 10, cfg)\n",
        "    for j in range(10):\n",
        "        img = samples[j].permute(1, 2, 0).cpu().numpy()\n",
        "        img = (img + 1) / 2\n",
        "        axes[i, j].imshow(np.clip(img, 0, 1))\n",
        "        axes[i, j].axis('off')\n",
        "        if j == 0:\n",
        "            axes[i, j].set_ylabel(f\"CFG={cfg}\", fontsize=12)\n",
        "\n",
        "plt.suptitle(\"Generated Samples with Different CFG Scales\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"outputs/colab_training/cfg_comparison.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Ô∏è‚É£ Save Model üíæ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model checkpoint\n",
        "checkpoint = {\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    \"config\": config,\n",
        "    \"epoch\": config[\"epochs\"],\n",
        "    \"history\": history\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, \"outputs/colab_training/model.pt\")\n",
        "print(\"‚úÖ Model saved to outputs/colab_training/model.pt\")\n",
        "\n",
        "# Save training history\n",
        "with open(\"outputs/colab_training/history.json\", \"w\") as f:\n",
        "    json.dump(history, f)\n",
        "print(\"‚úÖ Training history saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the model (for Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"outputs/colab_training/model.pt\")\n",
        "    print(\"üì• Model download started!\")\n",
        "except ImportError:\n",
        "    print(\"‚ÑπÔ∏è Not running in Colab, skipping download.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ Congratulations!\n",
        "\n",
        "You've successfully trained a SoFlow model! Key takeaways:\n",
        "\n",
        "- **One-step generation** works after training\n",
        "- **CFG scale** controls quality vs diversity\n",
        "- **Loss curves** show stable training\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. Try the [Inference Notebook](./SoFlow_Inference.ipynb) to generate more samples\n",
        "2. Increase training epochs for better quality\n",
        "3. Try larger model sizes if you have more GPU memory\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**Made with ‚ù§Ô∏è for the ML community**\n",
        "\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
